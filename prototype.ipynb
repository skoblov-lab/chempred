{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from itertools import starmap, chain\n",
    "from collections import Counter\n",
    "import operator as op\n",
    "\n",
    "import numpy as np\n",
    "from fn import F\n",
    "\n",
    "from chempred import chemdner\n",
    "from chempred import preprocessing as pp\n",
    "from chempred import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonpos = 3\n",
    "flanking = False\n",
    "window = 5\n",
    "maxlen = 500\n",
    "class_mapping = {\n",
    "    \"OTHER\": 0,\n",
    "    \"ABBREVIATION\": 1,\n",
    "    \"FAMILY\": 2,\n",
    "    \"FORMULA\": 3,\n",
    "    \"IDENTIFIER\": 4,\n",
    "    \"MULTIPLE\": 5,\n",
    "    \"NO CLASS\": 6,\n",
    "    \"SYSTEMATIC\": 7,\n",
    "    \"TRIVIAL\": 8\n",
    "}\n",
    "binary_class_mapping = {cls: 0 if cls == \"OTHER\" else 1 for cls in class_mapping}\n",
    "positive_classes = {cls for cls in class_mapping if cls != \"OTHER\"}\n",
    "\n",
    "abstracts = chemdner.read_abstracts(\"chemdner_corpus/training.abstracts.txt\")\n",
    "abstract_annotations = chemdner.read_annotations(\"chemdner_corpus/training.annotations.txt\")\n",
    "aligned = list(chemdner.align_abstracts_and_annotations(abstracts, abstract_annotations))\n",
    "data = (F(map, chemdner.flatten_aligned_pair) >> chain.from_iterable >> list)(aligned)\n",
    "nonempty = [(id_, src, text, annotations) \n",
    "            for id_, src, text, annotations in data if annotations]\n",
    "ids = [id_ for id_, *_ in nonempty]\n",
    "texts = [text for *_, text, _ in nonempty]\n",
    "text_annotations = [chemdner.annotate_text(text, annotations, src, True) \n",
    "                    for _, src, text, annotations in nonempty]\n",
    "\n",
    "targets = [pp.sample_targets(positive_classes, annotations, nonpos) \n",
    "           for annotations in text_annotations]\n",
    "sampler = pp.make_sampler(maxlen=maxlen, width=window, flanking=flanking)\n",
    "samples_and_failures = (F(zip) \n",
    "                        >> (starmap, F(pp.sample_windows, sampler=sampler))\n",
    "                        >> list)(targets, text_annotations)\n",
    "samples = list(map(op.itemgetter(0), samples_and_failures))\n",
    "failures = list(map(op.itemgetter(1), samples_and_failures))\n",
    "\n",
    "encoded_texts = [[pp.encode_text(text, sample) for sample in samples_] \n",
    "                for text, samples_ in zip(texts, samples)]\n",
    "# encoded_classes = [[pp.encode_classes(class_mapping, sample) for sample in samples_] \n",
    "#                    for text, samples_ in zip(texts, samples)]\n",
    "encoded_classes = [[pp.encode_classes(binary_class_mapping, sample) for sample in samples_] \n",
    "                   for text, samples_ in zip(texts, samples)]\n",
    "\n",
    "joined_texts, masks_text = pp.join(list(chain.from_iterable(encoded_texts)))\n",
    "joined_classes, masks_classes = pp.join(list(chain.from_iterable(encoded_classes)))\n",
    "\n",
    "assert (masks_text == masks_classes).all()\n",
    "\n",
    "joined_classes_onehot = pp.maskfalse(pp.one_hot(joined_classes), masks_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Examine class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = [np.unique(cls, return_counts=True)[1] \n",
    "                for cls in chain.from_iterable(encoded_classes)]\n",
    "stacked_counts = np.vstack([counts if len(counts) == 2 else np.array([counts[0], 0]) \n",
    "                            for counts in class_counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4647000, 2084937])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_counts.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as k\n",
    "from keras import losses\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "\n",
    "maxlen = joined_texts.shape[1]\n",
    "nchar = pp.MAXCHAR + 1\n",
    "# ncls = len(class_mapping)\n",
    "ncls = len(set(binary_class_mapping.values()))\n",
    "batchsize = 400\n",
    "\n",
    "l_in = layers.Input(shape=(maxlen,), name=\"l_in\")\n",
    "l_emb = layers.Embedding(nchar, 50, mask_zero=True, input_length=maxlen)(l_in)\n",
    "l_rec = model.build_rec([200, 300], [0, 0.1], [0, 0.1])(l_emb)\n",
    "l_out = layers.TimeDistributed(\n",
    "    layers.Dense(ncls, activation='softmax'), name=\"l_out\")(l_rec)\n",
    "rnn = models.Model(l_in, l_out)\n",
    "rnn.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "# filepath = \"models/emb-length-800/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "# checkpoint = callbacks.ModelCheckpoint(filepath, monitor=\"val_acc\", verbose=1, \n",
    "#                                        save_best_only=True, mode=\"max\")\n",
    "# reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3,min_lr=0.0001)\n",
    "\n",
    "# callbacks_ = [checkpoint]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 169445 samples, validate on 18828 samples\n",
      "Epoch 1/30\n",
      "  3400/169445 [..............................] - ETA: 4791s - loss: 1.4584 - acc: 0.6577"
     ]
    }
   ],
   "source": [
    "# rnn.fit(padded_samples_train, masked_cls_train, batch_size=batchsize, epochs=30, verbose=1,\n",
    "#           validation_data=(padded_samples_test, masked_cls_test), callbacks=callbacks_)\n",
    "\n",
    "rnn.fit(joined_texts, joined_classes_onehot, batch_size=batchsize, epochs=30, verbose=1,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(test2_x_encoded[:1].argmin(axis=2))\n",
    "print(net2.predict(test2_x_encoded[:1]).argmax(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
