{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilia/.venvs/py3/lib/python3.5/site-packages/ggplot/utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n",
      "/home/ilia/.venvs/py3/lib/python3.5/site-packages/ggplot/stats/smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "/home/ilia/.venvs/py3/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from itertools import starmap, chain\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import ggplot\n",
    "from fn import F\n",
    "\n",
    "from chempred.chemdner import read_abstracts, read_annotations, pair, annotate_abstract\n",
    "from chempred import preprocessing as pp\n",
    "import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window = 5\n",
    "max_sample_len = 800\n",
    "\n",
    "def len_filter(sequence, maxlen=max_sample_len):\n",
    "    return [obj for obj in sequence if len(obj) <= maxlen]\n",
    "\n",
    "\n",
    "abstracts_train = read_abstracts(\"chemdner_corpus/training.abstracts.txt\")\n",
    "anno_train = read_annotations(\"chemdner_corpus/training.annotations.txt\")\n",
    "pairs_train = list(zip(abstracts_train, pair(abstracts_train, anno_train)))\n",
    "annotated_abstracts_train = list(starmap(F(annotate_abstract, guided=True), pairs_train))\n",
    "\n",
    "abstracts_test = read_abstracts(\"chemdner_corpus/evaluation.abstracts.txt\")\n",
    "anno_test = read_annotations(\"chemdner_corpus/evaluation.annotations.txt\")\n",
    "pairs_test = list(zip(abstracts_test, pair(abstracts_test, anno_test)))\n",
    "annotated_abstracts_test = list(starmap(F(annotate_abstract, guided=True), pairs_test))\n",
    "\n",
    "pos_cls = Counter(\n",
    "    r[-1] for r in chain.from_iterable(anno for _, anno in anno_train + anno_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_items = [anno[3] for anno in \n",
    "                   chain.from_iterable(items for _, items in anno_train + anno_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6-(1,1,5-trimethyl-5α-hydroxycyclohexanyl)-6'-(1',1',5'-trimethyl-2'β-hydroxycyclohexanyl)-9,13,9',13'-tetramethyloctadec-7,9,11,13,15,7',9',11',13'-nonene-5α-D-arabinopyranosyl(2a → 1b)-β-D-arabinopyranosyl-(2b → 1c)-β-D-arabinopyranosyl-2'-β-D-arabinopyranosyl-(2d → 1e)-α-D-arabinopyranosyl-(2e → 1f)-α-D-arabinopyranoside\n"
     ]
    }
   ],
   "source": [
    "print(max(annotated_items, key=lambda x: len(x.encode())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO rename generate_training_samples\n",
    "joined_samples_train, joined_cls_train = pp.join_tokens_in_samples(\n",
    "    *pp.generate_training_samples(annotated_abstracts_train, pos_cls, window, False))\n",
    "samples_train, cls_train = map(len_filter, [joined_samples_train, joined_cls_train])\n",
    "joined_samples_test, joined_cls_test = pp.join_tokens_in_samples(\n",
    "    *pp.generate_training_samples(annotated_abstracts_test, pos_cls, window, False))\n",
    "samples_test, cls_test = map(len_filter, [joined_samples_test, joined_cls_test])\n",
    "# max_sample_len = max(map(len, samples_train+samples_test))\n",
    "\n",
    "padded_samples_train, padded_cls_train, masks_train = pp.pad(samples_train, cls_train, \n",
    "                                                             max_sample_len)\n",
    "padded_samples_test, padded_cls_test, masks_test = pp.pad(samples_test, cls_test, \n",
    "                                                          max_sample_len)\n",
    "\n",
    "# onehot_samples_train, onehot_cls_train = map(\n",
    "#     pp.encode_one_hot, [padded_samples_train, padded_cls_train])\n",
    "# masked_samples_train = pp.mask_array(onehot_samples_train, masks_train)\n",
    "# masked_cls_train = pp.mask_array(onehot_cls_train, masks_train)\n",
    "\n",
    "# onehot_samples_test, onehot_cls_test = map(\n",
    "#     pp.encode_one_hot, [padded_samples_test, padded_cls_test])\n",
    "# masked_samples_test = pp.mask_array(onehot_samples_test, masks_test)\n",
    "# masked_cls_test = pp.mask_array(onehot_cls_test, masks_test)\n",
    "\n",
    "onehot_cls_train = pp.encode_one_hot(padded_cls_train)\n",
    "masked_cls_train = pp.mask_array(onehot_cls_train, masks_train)\n",
    "\n",
    "onehot_cls_test = pp.encode_one_hot(padded_cls_test)\n",
    "masked_cls_test = pp.mask_array(onehot_cls_test, masks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143616, 500)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_samples_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34, 11],\n",
       "       [36, 11],\n",
       "       [33, 11],\n",
       "       [29, 11],\n",
       "       [29, 11],\n",
       "       [26,  9],\n",
       "       [24,  9],\n",
       "       [24,  9],\n",
       "       [18,  9],\n",
       "       [22,  9]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_counts = np.vstack([np.unique(cls, return_counts=True)[1] for cls in \n",
    "#                           (padded_cls[mask] for padded_cls, mask in zip(padded_classes, masks))])\n",
    "# class_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143616, (143616, 800), 123380, (123380, 800))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joined_samples_train), padded_samples_train.shape, len(joined_samples_test), padded_samples_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as k\n",
    "from keras import losses\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 13000/143616 [=>............................] - ETA: 7319s - loss: 0.5395 - acc: 0.7239"
     ]
    }
   ],
   "source": [
    "maxlen = padded_samples_train.shape[1]\n",
    "nchar = 256\n",
    "ncls = 2\n",
    "nrec = 2\n",
    "batchsize = 200\n",
    "\n",
    "l_in = layers.Input(shape=(maxlen,), name=\"l_in\")\n",
    "l_emb = layers.Embedding(nchar, 50, mask_zero=True, input_length=maxlen)(l_in)\n",
    "\n",
    "# model = models.Model(l_in, l_emb)\n",
    "\n",
    "# model.predict(padded_samples_train[:1]).shape\n",
    "\n",
    "# # l_mask = layers.Masking(mask_value=0, name=\"l_mask\")(l_in)\n",
    "l_rec = prototype.build_rec([200, 200], [0, 0.1], [0, 0.1])(l_emb)\n",
    "l_out = layers.TimeDistributed(\n",
    "    layers.Dense(ncls, activation='softmax'), name=\"l_out\")(l_rec)\n",
    "model = models.Model(l_in, l_out)\n",
    "model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "filepath = \"models/emb-length-800/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor=\"val_acc\", verbose=1, \n",
    "                                       save_best_only=True, mode=\"max\")\n",
    "# # reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3,min_lr=0.0001)\n",
    "\n",
    "callbacks_ = [checkpoint]\n",
    "\n",
    "model.fit(padded_samples_train, masked_cls_train, batch_size=batchsize, epochs=30, verbose=1,\n",
    "          validation_data=(padded_samples_test, masked_cls_test), callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(test2_x_encoded[:1].argmin(axis=2))\n",
    "print(net2.predict(test2_x_encoded[:1]).argmax(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
