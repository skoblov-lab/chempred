{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from itertools import starmap, chain\n",
    "from collections import Counter\n",
    "import operator as op\n",
    "\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "from fn import F\n",
    "\n",
    "from chempred import chemdner\n",
    "from chempred import preprocessing as pp\n",
    "from chempred import model\n",
    "from chempred import training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODELS = \"models\"\n",
    "ABSTRACTS = \"abstracts\"\n",
    "ANNOTATIONS = \"annotations\"\n",
    "DETECTOR = \"detector\"\n",
    "TAGGER = \"tagger\"\n",
    "\n",
    "NCHAR = pp.MAXCHAR + 1\n",
    "EMBED = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = \"testdata/config-detector.json\"\n",
    "config = training.read_config(detector)\n",
    "if set(config.mapping.values()) != {0, 1}:\n",
    "    raise ValueError(\"The detector's mapping must be binary\")\n",
    "ncls = 2\n",
    "\n",
    "# read training data\n",
    "train_abstracts = chemdner.read_abstracts(config.train_data[ABSTRACTS])\n",
    "train_anno = chemdner.read_annotations(config.train_data[ANNOTATIONS])\n",
    "train_ids, train_samples, train_fail, train_x, train_y, train_mask = (\n",
    "    training.process_data(train_abstracts, train_anno, config.window,\n",
    "                          config.maxlen, config.nonpositive,\n",
    "                          config.mapping, config.positive)\n",
    ")\n",
    "# read testing data\n",
    "test_abstracts = chemdner.read_abstracts(\n",
    "    config.test_data[ABSTRACTS])\n",
    "test_anno = chemdner.read_annotations(\n",
    "    config.test_data[ANNOTATIONS])\n",
    "test_ids, test_samples, test_fail, test_x, test_y, test_mask = (\n",
    "    training.process_data(test_abstracts, test_anno, config.window,\n",
    "                          config.maxlen, config.nonpositive,\n",
    "                          config.mapping, config.positive)\n",
    ")\n",
    "\n",
    "train_y_onehot = pp.one_hot(train_y)\n",
    "test_y_onehot = pp.one_hot(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((158, 500), (155, 500))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_in = layers.Input(shape=(config.maxlen,), name=\"l_in\")\n",
    "l_emb = layers.Embedding(NCHAR, EMBED, mask_zero=True,\n",
    "                         input_length=config.maxlen)(l_in)\n",
    "l_rec = model.build_rec(config.nsteps, config.in_drop,\n",
    "                        config.rec_drop)(l_emb)\n",
    "l_out = layers.TimeDistributed(\n",
    "    layers.Dense(ncls, activation='softmax'), name=\"l_out\")(l_rec)\n",
    "detector_model = models.Model(l_in, l_out)\n",
    "detector_model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\",\n",
    "                       metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "with training.training(\"testdata\", \"model\") as (destination, weights):\n",
    "    # save architecture\n",
    "    detector_json = detector_model.to_json()\n",
    "    with open(destination, \"w\") as json_file:\n",
    "        json_file.write(detector_json)\n",
    "    checkpoint = callbacks.ModelCheckpoint(weights, monitor=\"val_acc\",\n",
    "                                           verbose=1, mode=\"max\",\n",
    "                                           save_best_only=True)\n",
    "    detector_model.fit(train_x, train_y_onehot, callbacks=[checkpoint],\n",
    "                       validation_data=(test_x, test_y_onehot), verbose=1,\n",
    "                       epochs=config.epochs, batch_size=config.batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Examine class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_counts = [np.unique(cls, return_counts=True)[1] \n",
    "#                 for cls in chain.from_iterable(encoded_classes)]\n",
    "# stacked_counts = np.vstack([counts if len(counts) == 2 else np.array([counts[0], 0]) \n",
    "#                             for counts in class_counts])\n",
    "# stacked_counts.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(test2_x_encoded[:1].argmin(axis=2))\n",
    "print(net2.predict(test2_x_encoded[:1]).argmax(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
